{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd5fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd3b346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 252)\n",
      "(1459, 251)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"new data/train_data_new.csv\")\n",
    "test_data = pd.read_csv(\"new data/test_data_new.csv\")\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b1af0",
   "metadata": {},
   "source": [
    "将训练数据划分为训练集和验证集用来调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a997acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_label = train_data['SalePrice']\n",
    "train_features = train_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37a46b",
   "metadata": {},
   "source": [
    "定义K折交叉验证和评估指标，本次Kaggle比赛的官方评估指标是rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6260ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X_train):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y_train, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b7acd",
   "metadata": {},
   "source": [
    "## GBDT模型调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590182f3",
   "metadata": {},
   "source": [
    "先用初始参数拟合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9193362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始参数训练集rmse =  0.0765984934729955\n",
      "初始参数测试集rmse =  0.17173252389215457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "model = gbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"初始参数训练集rmse = \", score_train)\n",
    "print(\"初始参数测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849a31a",
   "metadata": {},
   "source": [
    "训练集rmse比测试集rmse低很多，可能存在过拟合的情况，我们希望能够通过调参改变这种情况"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6d355",
   "metadata": {},
   "source": [
    "调参按照如下顺序调节，先调节类参数，再调节弱学习器参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4768aaed",
   "metadata": {},
   "source": [
    "先调类参数learning_rate和n_estimators，我们还需要设置其它参数的默认值\n",
    "\n",
    "对于learning_rate和n_estimators而言，可以先将学习率固定为0.1，搜索迭代次数\n",
    "\n",
    "由于我们样本数只有1458个，min_samples_split的取值范围一般是样本数目的0.5%-1%之间，所以可以取7到14，我们取5作为默认值，后续可以逐渐增加\n",
    "\n",
    "min_samples_leaf的取值凭感觉取一个数只要不造成过拟合即可，我们也取5作为默认值\n",
    "\n",
    "由于样本数目不多，在sklearn中max_depth默认为3，取默认值即可\n",
    "\n",
    "max_features一般默认取sqrt，subsample一般默认取0.8，由于数据集比较多的离群值，所以loss取huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4828ceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'n_estimators': 100}\n",
      "0.19407874805162664\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {'n_estimators': [i for i in range(100, 500, 100)]}\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.1, \n",
    "                                min_samples_split=5,\n",
    "                                min_samples_leaf=5,\n",
    "                                max_depth=3,\n",
    "                                max_features='sqrt', \n",
    "                                subsample=0.8,\n",
    "                                loss='huber',\n",
    "                                random_state=42)\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_test1, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434727a",
   "metadata": {},
   "source": [
    "得到最佳迭代次数为100，此时学习率为0.1\n",
    "\n",
    "这两个参数在后续可以成比例缩放进行调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0dcdce",
   "metadata": {},
   "source": [
    "接下来调节弱学习器的参数，对结果影响最大的参数应该优先调节，弱学习器参数的调参顺序如下\n",
    "\n",
    "1.调节max_depth和 min_samples_split\n",
    "\n",
    "2.调节min_samples_leaf\n",
    "\n",
    "3.调节max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a09c83",
   "metadata": {},
   "source": [
    "调参max_depth和min_samples_split\n",
    "\n",
    "由于样本数量不多所以我们将max_depth的取值范围设为[2, 4]\n",
    "\n",
    "min_samples_split的取值范围设为[5, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2475d609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "{'max_depth': 2, 'min_samples_split': 11}\n",
      "0.21598003619187325\n"
     ]
    }
   ],
   "source": [
    "param_test2 = {'max_depth': [i for i in range(2, 5)],\n",
    "              'min_samples_split': [i for i in range(5, 16, 2)]}\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.1, \n",
    "                                n_estimators=100,\n",
    "                                min_samples_leaf=5,\n",
    "                                max_features='sqrt', \n",
    "                                subsample=0.8,\n",
    "                                loss='huber',\n",
    "                                random_state=42)\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_test2, scoring=make_scorer(rmse), cv=5, verbose=True, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5da2a1c",
   "metadata": {},
   "source": [
    "得到了max_depth为2，由于样本数比较少，我认为这是合理的，min_samples_split为11，我们可以将max_depth确定下来，但是min_samples_split受到其它参数的影响还不能确定下来"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b4c511",
   "metadata": {},
   "source": [
    "接下来我们对划分最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf进行调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acdbbd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "{'min_samples_leaf': 19, 'min_samples_split': 5}\n",
      "0.21920648938938977\n"
     ]
    }
   ],
   "source": [
    "param_test3 = {'min_samples_split': [i for i in range(5, 20, 2)],\n",
    "              'min_samples_leaf': [i for i in range(5, 20, 2)]}\n",
    "                \n",
    "gbr = GradientBoostingRegressor(learning_rate=0.1, \n",
    "                                n_estimators=100,\n",
    "                                max_depth=2,\n",
    "                                max_features='sqrt', \n",
    "                                subsample=0.8,\n",
    "                                loss='huber',\n",
    "                                random_state=42)\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_test3, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6479b3b",
   "metadata": {},
   "source": [
    "得到了min_samples_leaf为19，min_samples_split为5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595c07f",
   "metadata": {},
   "source": [
    "现在我们已经得到了绝大部分参数，可以先用验证集进行验证查看调参的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91fec09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "部分调参后训练集rmse =  0.16959425123075478\n",
      "部分调参后测试集rmse =  0.22097611132153475\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(learning_rate=0.1, \n",
    "                                n_estimators=100,\n",
    "                                max_depth=2,\n",
    "                                min_samples_leaf=19,\n",
    "                                min_samples_split=5,\n",
    "                                max_features='sqrt', \n",
    "                                subsample=0.8,\n",
    "                                loss='huber',\n",
    "                                random_state=42)\n",
    "\n",
    "model = gbr.fit(X_train, y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"部分调参后训练集rmse = \", score_train)\n",
    "print(\"部分调参后测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62268fc9",
   "metadata": {},
   "source": [
    "可以看到通过部分调参后我们的训练集和测试集的rmse有所下降，但是有效的解决了过拟合的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4ad74",
   "metadata": {},
   "source": [
    "接下来我们再对max_features和subsample进行调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "018c395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'log2'}\n",
      "0.24299647040333908\n"
     ]
    }
   ],
   "source": [
    "param_test4 = {'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.1, \n",
    "                                n_estimators=100,\n",
    "                                max_depth=2,\n",
    "                                min_samples_leaf=19,\n",
    "                                min_samples_split=5, \n",
    "                                subsample=0.8,\n",
    "                                loss='huber',\n",
    "                                random_state=42)\n",
    "grid_search = GridSearchCV(gbr, param_test4, scoring=make_scorer(rmse), cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d705ccec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.5}\n",
      "0.2462582146591538\n"
     ]
    }
   ],
   "source": [
    "param_test5 = {'subsample': np.arange(0.5, 0.9, 0.05)}\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.1, \n",
    "                                n_estimators=100,\n",
    "                                max_depth=2,\n",
    "                                min_samples_leaf=19,\n",
    "                                min_samples_split=5, \n",
    "                                max_features='log2',\n",
    "                                loss='huber',\n",
    "                                random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(gbr, param_test5, scoring=make_scorer(rmse), cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0550c9",
   "metadata": {},
   "source": [
    "将得到的所有参数放入模型，并同时调整学习率和迭代次数，查看模型训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a73a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成调参后训练集rmse =  0.1301719365550433\n",
      "完成调参后测试集rmse =  0.20128830666446296\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(learning_rate=0.05, \n",
    "                                n_estimators=500,\n",
    "                                max_depth=2,\n",
    "                                min_samples_leaf=19,\n",
    "                                min_samples_split=5,\n",
    "                                max_features='log2', \n",
    "                                subsample=0.5,\n",
    "                                loss='huber',\n",
    "                                random_state=42)\n",
    "\n",
    "model = gbr.fit(X_train, y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"完成调参后训练集rmse = \", score_train)\n",
    "print(\"完成调参后测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc075354",
   "metadata": {},
   "source": [
    "## 随机森林模型调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971334f3",
   "metadata": {},
   "source": [
    "随机森林模型的参数比GBDT模型的参数要少，也可以用类似的方式调参得到，这里就不重复演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "febd82ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成调参后训练集rmse =  0.10171651006696977\n",
      "完成调参后袋外分数 =  0.7644437660923032\n",
      "完成调参后测试集rmse =  0.20917457525260985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=500,\n",
    "                          max_depth=12,\n",
    "                          min_samples_split=5,\n",
    "                          min_samples_leaf=5,\n",
    "                          max_features=None,\n",
    "                          oob_score=True,\n",
    "                          random_state=42)\n",
    "\n",
    "model = rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"完成调参后训练集rmse = \", score_train)\n",
    "print(\"完成调参后袋外分数 = \", model.oob_score_)\n",
    "print(\"完成调参后测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97accbd5",
   "metadata": {},
   "source": [
    "实际上由于随机森林有袋外数据的存在可以不用划分训练集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159208bb",
   "metadata": {},
   "source": [
    "## XGBoost模型调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce14961",
   "metadata": {},
   "source": [
    "同样先用初始参数拟合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e4d6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始参数训练集rmse =  0.00041859204434890906\n",
      "初始参数测试集rmse =  0.20088078912490726\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "xgboost = XGBRegressor(objective='reg:squarederror',\n",
    "                       random_state=42)\n",
    "\n",
    "model = xgboost.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"初始参数训练集rmse = \", score_train)\n",
    "print(\"初始参数测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c1c3d0",
   "metadata": {},
   "source": [
    "可以看到存在严重的过拟合问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7cee57",
   "metadata": {},
   "source": [
    "在XGBoost调参中也是先调类参数，再调弱学习器参数\n",
    "\n",
    "类参数与GBDT类似，最重要的是迭代次数n_estimators和学习率learning_rate\n",
    "\n",
    "弱学习器参数对模型影响最大的参数如下\n",
    "1. 树的最大深度max_depth\n",
    "2. 最小的子节点权重阈值min_child_weight\n",
    "3. 决策树分裂所带来的损失减小阈值gamma\n",
    "\n",
    "一般按照顺序先调这三个参数，如果这三个参数调整之后可以解决过拟合问题且模型效果还不错，剩下的参数可以设为默认值\n",
    "\n",
    "剩下的参数包括子采样参数subsample，整棵树的特征采样比例colsample_bytree，正则化参数reg_alpha/reg_lambda等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86f1cfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'n_estimators': 100}\n",
      "0.17953909458338022\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {'n_estimators': [i for i in range(100, 500, 100)]}\n",
    "\n",
    "xgboost = XGBRegressor(learning_rate=0.1, \n",
    "                       max_depth=5,\n",
    "                       min_child_weight=1,\n",
    "                       gamma=0,\n",
    "                       subsample=0.8,\n",
    "                       colsample_bytree=0.8,\n",
    "                       reg_alpha=0,\n",
    "                       reg_lambda=1,\n",
    "                       objective='reg:squarederror',\n",
    "                       random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgboost, param_grid=param_test1, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8811099d",
   "metadata": {},
   "source": [
    "接下来调max_depth和min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d9c2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "{'max_depth': 9, 'min_child_weight': 3}\n",
      "0.18068171277629458\n"
     ]
    }
   ],
   "source": [
    "param_test2 = {'max_depth': [i for i in range(3, 10)], \n",
    "               'min_child_weight': [i for i in range(3, 10)]}\n",
    "\n",
    "xgboost = XGBRegressor(n_estimators=100,\n",
    "                       learning_rate=0.1, \n",
    "                       gamma=0,\n",
    "                       subsample=0.8,\n",
    "                       colsample_bytree=0.8,\n",
    "                       reg_alpha=0,\n",
    "                       reg_lambda=1,\n",
    "                       objective='reg:squarederror',\n",
    "                       random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgboost, param_grid=param_test2, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e070c",
   "metadata": {},
   "source": [
    "得到max_depth为9，min_child_weight为3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823df95d",
   "metadata": {},
   "source": [
    "接下来调gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26db123f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "{'gamma': 0.8000000000000003}\n",
      "0.19624260758369796\n"
     ]
    }
   ],
   "source": [
    "param_test3 = {'gamma': np.arange(0.2, 0.9, 0.1)}\n",
    "\n",
    "xgboost = XGBRegressor(n_estimators=100,\n",
    "                       learning_rate=0.1, \n",
    "                       max_depth=9,\n",
    "                       min_child_weight=3,\n",
    "                       subsample=0.8,\n",
    "                       colsample_bytree=0.8,\n",
    "                       reg_alpha=0,\n",
    "                       reg_lambda=1,\n",
    "                       objective='reg:squarederror',\n",
    "                       random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgboost, param_grid=param_test3, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc61cfd",
   "metadata": {},
   "source": [
    "得到gamma为0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab3ac465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "部分调参后训练集rmse =  0.14826534667430974\n",
      "部分调参后测试集rmse =  0.20633124732079536\n"
     ]
    }
   ],
   "source": [
    "xgboost = XGBRegressor(learning_rate=0.1,\n",
    "                       n_estimators=100,\n",
    "                       max_depth=9,\n",
    "                       min_child_weight=3,\n",
    "                       gamma=0.8,\n",
    "                       subsample=0.8,\n",
    "                       colsample_bytree=0.8,\n",
    "                       reg_alpha=0,\n",
    "                       reg_lambda=1,\n",
    "                       objective='reg:squarederror',\n",
    "                       random_state=42)\n",
    "\n",
    "model = xgboost.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"部分调参后训练集rmse = \", score_train)\n",
    "print(\"部分调参后测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ed6b6",
   "metadata": {},
   "source": [
    "可以看到已经解决了过拟合的问题，那么剩下的参数可以选择不调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee2a1fa",
   "metadata": {},
   "source": [
    "最后同时缩放类参数，提高模型的泛化能力，同时注意过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90b51f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成调参后训练集rmse =  0.14414262647675175\n",
      "完成调参后测试集rmse =  0.19746198376168503\n"
     ]
    }
   ],
   "source": [
    "xgboost = XGBRegressor(learning_rate=0.05,\n",
    "                       n_estimators=1000,\n",
    "                       max_depth=9,\n",
    "                       min_child_weight=3,\n",
    "                       gamma=0.8,\n",
    "                       subsample=0.8,\n",
    "                       colsample_bytree=0.8,\n",
    "                       reg_alpha=0,\n",
    "                       reg_lambda=1,\n",
    "                       objective='reg:squarederror',\n",
    "                       random_state=42)\n",
    "\n",
    "model = xgboost.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"完成调参后训练集rmse = \", score_train)\n",
    "print(\"完成调参后测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae1d7b7",
   "metadata": {},
   "source": [
    "## lightgbm模型调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7328b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始参数训练集rmse =  0.020193735388523044\n",
      "初始参数测试集rmse =  0.1718814611734789\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lightgbm = LGBMRegressor(objective='regression',\n",
    "                       random_state=42)\n",
    "\n",
    "model = lightgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"初始参数训练集rmse = \", score_train)\n",
    "print(\"初始参数测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21f73c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'n_estimators': 100}\n",
      "0.17193835548870867\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {'n_estimators': [i for i in range(100, 500, 100)]}\n",
    "\n",
    "lightgbm = LGBMRegressor(learning_rate=0.1, \n",
    "                         num_leaves=31,\n",
    "                         max_depth=5,\n",
    "                         min_child_weight=1,\n",
    "                         subsample=0.8,\n",
    "                         colsample_bytree=0.8,\n",
    "                         reg_alpha=0,\n",
    "                         reg_lambda=1,\n",
    "                         objective='regression',\n",
    "                         random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lightgbm, param_grid=param_test1, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9cd48",
   "metadata": {},
   "source": [
    "lightgbm中max_depth和num_leaves是相互影响的参数\n",
    "\n",
    "一般而言，num_leaves <= 2^n-1，其中n为max_depth的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8a3fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 77 candidates, totalling 385 fits\n",
      "{'max_depth': 6, 'num_leaves': 30}\n",
      "0.17211791364042112\n"
     ]
    }
   ],
   "source": [
    "param_test2 = {'max_depth': [i for i in range(3, 10)],\n",
    "              'num_leaves': [i for i in range(10, 31, 2)]}\n",
    "\n",
    "lightgbm = LGBMRegressor(learning_rate=0.1, \n",
    "                         n_estimators=100,\n",
    "                         min_child_weight=1,\n",
    "                         subsample=0.8,\n",
    "                         colsample_bytree=0.8,\n",
    "                         reg_alpha=0,\n",
    "                         reg_lambda=1,\n",
    "                         objective='regression',\n",
    "                         random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lightgbm, param_grid=param_test2, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be734bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "{'min_child_weight': 3}\n",
      "0.17211791364042112\n"
     ]
    }
   ],
   "source": [
    "param_test3 = {'min_child_weight': [i for i in range(3, 10)]}\n",
    "\n",
    "lightgbm = LGBMRegressor(learning_rate=0.1, \n",
    "                         n_estimators=100,\n",
    "                         max_depth=6,\n",
    "                         num_leaves=30,\n",
    "                         subsample=0.8,\n",
    "                         colsample_bytree=0.8,\n",
    "                         reg_alpha=0,\n",
    "                         reg_lambda=1,\n",
    "                         objective='regression',\n",
    "                         random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lightgbm, param_grid=param_test3, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38120bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "部分调参后训练集rmse =  0.030520437973626992\n",
      "部分调参后测试集rmse =  0.16665352013041423\n"
     ]
    }
   ],
   "source": [
    "lightgbm = LGBMRegressor(learning_rate=0.1, \n",
    "                         n_estimators=100,\n",
    "                         max_depth=6,\n",
    "                         num_leaves=30,\n",
    "                         min_child_weight=3,\n",
    "                         subsample=0.8,\n",
    "                         colsample_bytree=0.8,\n",
    "                         reg_alpha=0,\n",
    "                         reg_lambda=1,\n",
    "                         objective='regression',\n",
    "                         random_state=42)\n",
    "\n",
    "model = lightgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"部分调参后训练集rmse = \", score_train)\n",
    "print(\"部分调参后测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae731234",
   "metadata": {},
   "source": [
    "可以看到仍然存在过拟合的情况，我们还需要继续调剩下的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a532405a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'subsample': 0.5}\n",
      "0.17211791364042112\n"
     ]
    }
   ],
   "source": [
    "param_test4 = {'subsample': np.arange(0.5, 0.9, 0.1)}\n",
    "\n",
    "lightgbm = LGBMRegressor(learning_rate=0.1, \n",
    "                         n_estimators=100,\n",
    "                         max_depth=6,\n",
    "                         num_leaves=30,\n",
    "                         min_child_weight=3,\n",
    "                         colsample_bytree=0.8,\n",
    "                         reg_alpha=0,\n",
    "                         reg_lambda=1,\n",
    "                         objective='regression',\n",
    "                         random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lightgbm, param_grid=param_test4, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7b4bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'colsample_bytree': 0.5}\n",
      "0.17655370838035325\n"
     ]
    }
   ],
   "source": [
    "param_test5 = {'colsample_bytree': np.arange(0.5, 0.9, 0.1)}\n",
    "\n",
    "lightgbm = LGBMRegressor(learning_rate=0.1, \n",
    "                         n_estimators=100,\n",
    "                         max_depth=6,\n",
    "                         num_leaves=30,\n",
    "                         min_child_weight=3,\n",
    "                         subsample=0.5,\n",
    "                         reg_alpha=0,\n",
    "                         reg_lambda=1,\n",
    "                         objective='regression',\n",
    "                         random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lightgbm, param_grid=param_test5, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e323346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 275 candidates, totalling 1375 fits\n",
      "{'reg_alpha': 10, 'reg_lambda': 24}\n",
      "0.20524636352001685\n"
     ]
    }
   ],
   "source": [
    "param_test6 = {'reg_alpha': [i for i in range(0, 11)],\n",
    "              'reg_lambda': [i for i in range(1, 26)]}\n",
    "\n",
    "lightgbm = LGBMRegressor(learning_rate=0.1, \n",
    "                         n_estimators=100,\n",
    "                         max_depth=6,\n",
    "                         num_leaves=30,\n",
    "                         min_child_weight=3,\n",
    "                         subsample=0.5,\n",
    "                         colsample_bytree=0.5,\n",
    "                         objective='regression',\n",
    "                         random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lightgbm, param_grid=param_test6, scoring=make_scorer(rmse), cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c368c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成调参后训练集rmse =  0.15493532208240576\n",
      "完成调参后测试集rmse =  0.19966635030234303\n"
     ]
    }
   ],
   "source": [
    "lightgbm = LGBMRegressor(learning_rate=0.1, \n",
    "                         n_estimators=100,\n",
    "                         max_depth=6,\n",
    "                         num_leaves=30,\n",
    "                         min_child_weight=3,\n",
    "                         subsample=0.5,\n",
    "                         colsample_bytree=0.5,\n",
    "                         reg_alpha=10,\n",
    "                         reg_lambda=24,\n",
    "                         objective='regression',\n",
    "                         random_state=42)\n",
    "\n",
    "model = lightgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"完成调参后训练集rmse = \", score_train)\n",
    "print(\"完成调参后测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca8be7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成调参后训练集rmse =  0.14947870244676917\n",
      "完成调参后测试集rmse =  0.19495610296499724\n"
     ]
    }
   ],
   "source": [
    "lightgbm = LGBMRegressor(learning_rate=0.05, \n",
    "                         n_estimators=800,\n",
    "                         max_depth=6,\n",
    "                         num_leaves=30,\n",
    "                         min_child_weight=3,\n",
    "                         subsample=0.5,\n",
    "                         colsample_bytree=0.5,\n",
    "                         reg_alpha=10,\n",
    "                         reg_lambda=24,\n",
    "                         objective='regression',\n",
    "                         random_state=42)\n",
    "\n",
    "model = lightgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "score_train = rmse(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "score_val = rmse(y_val, y_pred_val)\n",
    "\n",
    "print(\"完成调参后训练集rmse = \", score_train)\n",
    "print(\"完成调参后测试集rmse = \", score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a7a17",
   "metadata": {},
   "source": [
    "可以看到调参后过拟合的情况有所改善并且模型精度有所提高"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
